{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation using RNN - Character Level\n",
    "\n",
    "To generate text using RNN, we need a to convert raw text to a supervised learning problem format.\n",
    "\n",
    "Take, for example, the following corpus:\n",
    "\n",
    "\"Her brother shook his head incredulously\"\n",
    "\n",
    "First we need to divide the data into tabular format containing input (X) and output (y) sequences. In case of a character level model, the X and y will look like this:\n",
    "\n",
    "|      X     |  Y  |\n",
    "|------------|-----|\n",
    "|    Her b   |  r  |\n",
    "|    er br   |  o  |\n",
    "|    r bro   |  t  |\n",
    "|     brot   |  h  |\n",
    "|    broth   |  e  |\n",
    "|    .....   |  .  |\n",
    "|    .....   |  .  |\n",
    "|    ulous   |  l  |\n",
    "|    lousl   |  y  |\n",
    "\n",
    "Note that in the above problem, the sequence length of X is five characters and that of y is one character. Hence, this is a many-to-one architecture. We can, however, change the number of input characters to any number of characters depending on the type of problem.\n",
    "\n",
    "A model is trained on such data. To generate text, we simply give the model any five characters using which it predicts the next character. Then it appends the predicted character to the input sequence (on the extreme right of the sequence) and discards the first character (character on extreme left of the sequence). Then it predicts again using the new sequence and the cycle continues until a fix number of iterations. An example is shown below:\n",
    "\n",
    "Seed text: \"incre\"\n",
    "\n",
    "|      X                                            |  Y                       |\n",
    "|---------------------------------------------------|--------------------------|\n",
    "|                        incre                      |    < predicted char 1 >  |\n",
    "|               ncre < predicted char 1 >              |    < predicted char 2 >  |\n",
    "|       cre< predicted char 1 > < predicted char 2 >   |    < predicted char 3 >  |\n",
    "|       re< predicted char 1 >< predicted char 2 > < predicted char 3 >   |    < predicted char 4 >  |\n",
    "|                      ...                          |            ...           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "1. Preprocess data\n",
    "2. LSTM model\n",
    "3. Generate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Sa28LJ6YqdD",
    "outputId": "ae782caf-f9d1-43fe-aa32-4f2ccf02cfe0"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a C code generator by training an RNN on a huge corpus of C code (the linux kernel code). You can download the C code used as source text from the following link:\n",
    "https://github.com/torvalds/linux/tree/master/kernel\n",
    "\n",
    "We have already downloaded the entire kernel folder and stored in a local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "hO1StR3rX72I",
    "outputId": "42079a21-0a71-4fba-c90a-b13e3acbb909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitignore', 'acct.c', 'async.c', 'audit.c', 'audit.h', 'auditfilter.c', 'auditsc.c', 'audit_fsnotify.c', 'audit_tree.c', 'audit_watch.c', 'backtracetest.c', 'bounds.c', 'bpf', 'capability.c', 'cfi.c', 'cgroup', 'compat.c', 'configs', 'configs.c', 'context_tracking.c', 'cpu.c', 'cpu_pm.c', 'crash_core.c', 'crash_dump_dm_crypt.c', 'crash_reserve.c', 'cred.c', 'debug', 'delayacct.c', 'dma', 'dma.c', 'elfcorehdr.c', 'entry', 'events', 'exec_domain.c', 'exit.c', 'exit.h', 'extable.c', 'fail_function.c', 'fork.c', 'freezer.c', 'futex', 'gcov', 'gen_kheaders.sh', 'groups.c', 'hung_task.c', 'iomem.c', 'irq', 'irq_work.c', 'jump_label.c', 'kallsyms.c', 'kallsyms_internal.h', 'kallsyms_selftest.c', 'kallsyms_selftest.h', 'kcmp.c', 'Kconfig.freezer', 'Kconfig.hz', 'Kconfig.kexec', 'Kconfig.locks', 'Kconfig.preempt', 'kcov.c', 'kcsan', 'kexec.c', 'kexec_core.c', 'kexec_elf.c', 'kexec_file.c', 'kexec_handover.c', 'kexec_internal.h', 'kheaders.c', 'kprobes.c', 'ksyms_common.c', 'ksysfs.c', 'kthread.c', 'latencytop.c', 'livepatch', 'locking', 'Makefile', 'module', 'module_signature.c', 'notifier.c', 'nsproxy.c', 'padata.c', 'panic.c', 'params.c', 'pid.c', 'pid_namespace.c', 'pid_sysctl.h', 'power', 'printk', 'profile.c', 'ptrace.c', 'range.c', 'rcu', 'reboot.c', 'regset.c', 'relay.c', 'resource.c', 'resource_kunit.c', 'rseq.c', 'scftorture.c', 'sched', 'scs.c', 'seccomp.c', 'signal.c', 'smp.c', 'smpboot.c', 'smpboot.h', 'softirq.c', 'stackleak.c', 'stacktrace.c', 'static_call.c', 'static_call_inline.c', 'stop_machine.c', 'sys.c', 'sysctl-test.c', 'sysctl.c', 'sys_ni.c', 'taskstats.c', 'task_work.c', 'time', 'torture.c', 'trace', 'tracepoint.c', 'tsacct.c', 'ucount.c', 'uid16.c', 'uid16.h', 'umh.c', 'up.c', 'user-return-notifier.c', 'user.c', 'usermode_driver.c', 'user_namespace.c', 'utsname.c', 'utsname_sysctl.c', 'vhost_task.c', 'vmcore_info.c', 'watchdog.c', 'watchdog_buddy.c', 'watchdog_perf.c', 'watch_queue.c', 'workqueue.c', 'workqueue_internal.h']\n"
     ]
    }
   ],
   "source": [
    "# set path where C files reside\n",
    "\n",
    "path = r\"kernel\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "file_names = os.listdir()\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jg9HW8HwYlga",
    "outputId": "851307c1-b3f1-4fc6-c191-76962a66052b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acct.c', 'async.c', 'audit.c', 'auditfilter.c', 'auditsc.c', 'audit_fsnotify.c', 'audit_tree.c', 'audit_watch.c', 'backtracetest.c', 'bounds.c', 'capability.c', 'cfi.c', 'compat.c', 'configs.c', 'context_tracking.c', 'cpu.c', 'cpu_pm.c', 'crash_core.c', 'crash_dump_dm_crypt.c', 'crash_reserve.c', 'cred.c', 'delayacct.c', 'dma.c', 'elfcorehdr.c', 'exec_domain.c', 'exit.c', 'extable.c', 'fail_function.c', 'fork.c', 'freezer.c', 'groups.c', 'hung_task.c', 'iomem.c', 'irq_work.c', 'jump_label.c', 'kallsyms.c', 'kallsyms_selftest.c', 'kcmp.c', 'kcov.c', 'kexec.c', 'kexec_core.c', 'kexec_elf.c', 'kexec_file.c', 'kexec_handover.c', 'kheaders.c', 'kprobes.c', 'ksyms_common.c', 'ksysfs.c', 'kthread.c', 'latencytop.c', 'module_signature.c', 'notifier.c', 'nsproxy.c', 'padata.c', 'panic.c', 'params.c', 'pid.c', 'pid_namespace.c', 'profile.c', 'ptrace.c', 'range.c', 'reboot.c', 'regset.c', 'relay.c', 'resource.c', 'resource_kunit.c', 'rseq.c', 'scftorture.c', 'scs.c', 'seccomp.c', 'signal.c', 'smp.c', 'smpboot.c', 'softirq.c', 'stackleak.c', 'stacktrace.c', 'static_call.c', 'static_call_inline.c', 'stop_machine.c', 'sys.c', 'sysctl-test.c', 'sysctl.c', 'sys_ni.c', 'taskstats.c', 'task_work.c', 'torture.c', 'tracepoint.c', 'tsacct.c', 'ucount.c', 'uid16.c', 'umh.c', 'up.c', 'user-return-notifier.c', 'user.c', 'usermode_driver.c', 'user_namespace.c', 'utsname.c', 'utsname_sysctl.c', 'vhost_task.c', 'vmcore_info.c', 'watchdog.c', 'watchdog_buddy.c', 'watchdog_perf.c', 'watch_queue.c', 'workqueue.c']\n"
     ]
    }
   ],
   "source": [
    "# use regex to filter .c files\n",
    "import re\n",
    "c_names = \".*\\.c$\"\n",
    "\n",
    "c_files = list()\n",
    "\n",
    "for file in file_names:\n",
    "    if re.match(c_names, file):\n",
    "        c_files.append(file)\n",
    "\n",
    "print(c_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAbtuy5ZY87t"
   },
   "outputs": [],
   "source": [
    "# load all c code in a list\n",
    "full_code = list()\n",
    "for file in c_files:\n",
    "    code = open(file, \"r\", encoding='utf-8')\n",
    "    full_code.append(code.read())\n",
    "    code.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// SPDX-License-Identifier: GPL-2.0-or-later\n",
      "/* Task credentials management - see Documentation/security/credentials.rst\n",
      " *\n",
      " * Copyright (C) 2008 Red Hat, Inc. All Rights Reserved.\n",
      " * Written by David Howells (dhowells@redhat.com)\n",
      " */\n",
      "\n",
      "#define pr_fmt(fmt) \"CRED: \" fmt\n",
      "\n",
      "#include <linux/export.h>\n",
      "#include <linux/cred.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/sched.h>\n",
      "#include <linux/sched/coredump.h>\n",
      "#include <linux/key.h>\n",
      "#include <linux/keyctl.h>\n",
      "#include <linux/init_task.h>\n",
      "#include <linux/security.h>\n",
      "#include <linux/binfmts.h>\n",
      "#include <linux/cn_proc.h>\n",
      "#include <linux/uidgid.h>\n",
      "\n",
      "#if 0\n",
      "#define kdebug(FMT, ...)\t\t\t\t\t\t\\\n",
      "\tprintk(\"[%-5.5s%5u] \" FMT \"\\n\",\t\t\t\t\t\\\n",
      "\t       current->comm, current->pid, ##__VA_ARGS__)\n",
      "#else\n",
      "#define kdebug(FMT, ...)\t\t\t\t\t\t\\\n",
      "do {\t\t\t\t\t\t\t\t\t\\\n",
      "\tif (0)\t\t\t\t\t\t\t\t\\\n",
      "\t\tno_printk(\"[%-5.5s%5u] \" FMT \"\\n\",\t\t\t\\\n",
      "\t\t\t  current->comm, current->pid, ##__VA_ARGS__);\t\\\n",
      "} while (0)\n",
      "#endif\n",
      "\n",
      "static struct kmem_cache *cred_jar;\n",
      "\n",
      "/* init to 2 - one for init_task, one to ensure it is never freed */\n",
      "static struct group_info init_groups = { .usage = REFCOUNT_INIT(2) };\n",
      "\n",
      "/*\n",
      " * The initial credentials for the initial task\n",
      " */\n",
      "struct cred init_cred = {\n",
      "\t.usage\t\t\t= ATOMIC_INIT(4),\n",
      "\t.uid\t\t\t= GLOBAL_ROOT_UID,\n",
      "\t.gid\t\t\t= GLOBAL_ROOT_GID,\n",
      "\t.suid\t\t\t= GLOBAL_ROOT_UID,\n",
      "\t.sgid\t\t\t= GLOBAL_ROOT_GID,\n",
      "\t.euid\t\t\t= GLOBAL_ROOT_UID,\n",
      "\t.egid\t\t\t= GLOBAL_ROOT_GID,\n",
      "\t.fsuid\t\t\t= GLOBAL_ROOT_UID,\n",
      "\t.fsgid\t\t\t= GLOBAL_ROOT_GID,\n",
      "\t.securebits\t\t= SECUREBITS_DEFAULT,\n",
      "\t.cap_inheritable\t= CAP_EMPTY_SET,\n",
      "\t.cap_permitted\t\t= CAP_FULL_SET,\n",
      "\t.cap_effective\t\t= CAP_FULL_SET,\n",
      "\t.cap_bset\t\t= CAP_FULL_SET,\n",
      "\t.user\t\t\t= INIT_USER,\n",
      "\t.user_ns\t\t= &init_user_ns,\n",
      "\t.group_info\t\t= &init_groups,\n",
      "\t.ucounts\t\t= &init_ucounts,\n",
      "};\n",
      "\n",
      "/*\n",
      " * The RCU callback to actually dispose of a set of credentials\n",
      " */\n",
      "static void put_cred_rcu(struct rcu_head *rcu)\n",
      "{\n",
      "\tstruct cred *cred = container_of(rcu, struct cred, rcu);\n",
      "\n",
      "\tkdebug(\"put_cred_rcu(%p)\", cred);\n",
      "\n",
      "\tif (atomic_long_read(&cred->usage) != 0)\n",
      "\t\tpanic(\"CRED: put_cred_rcu() sees %p with usage %ld\\n\",\n",
      "\t\t      cred, atomic_long_read(&cred->usage));\n",
      "\n",
      "\tsecurity_cred_free(cred);\n",
      "\tkey_put(cred->session_keyring);\n",
      "\tkey_put(cred->process_keyring);\n",
      "\tkey_put(cred->thread_keyring);\n",
      "\tkey_put(cred->request_key_auth);\n",
      "\tif (cred->group_info)\n",
      "\t\tput_group_info(cred->group_info);\n",
      "\tfree_uid(cred->user);\n",
      "\tif (cred->ucounts)\n",
      "\t\tput_ucounts(cred->ucounts);\n",
      "\tput_user_ns(cred->user_ns);\n",
      "\tkmem_cache_free(cred_jar, cred);\n",
      "}\n",
      "\n",
      "/**\n",
      " * __put_cred - Destroy a set of credentials\n",
      " * @cred: The record to release\n",
      " *\n",
      " * Destroy a set of credentials on which no references remain.\n",
      " */\n",
      "void __put_cred(struct cred *cred)\n",
      "{\n",
      "\tkdebug(\"__put_cred(%p{%ld})\", cred,\n",
      "\t       atomic_long_read(&cred->usage));\n",
      "\n",
      "\tBUG_ON(atomic_long_read(&cred->usage) != 0);\n",
      "\tBUG_ON(cred == current->cred);\n",
      "\tBUG_ON(cred == current->real_cred);\n",
      "\n",
      "\tif (cred->non_rcu)\n",
      "\t\tput_cred_rcu(&cred->rcu);\n",
      "\telse\n",
      "\t\tcall_rcu(&cred->rcu, put_cred_rcu);\n",
      "}\n",
      "EXPORT_SYMBOL(__put_cred);\n",
      "\n",
      "/*\n",
      " * Clean up a task's credentials when it exits\n",
      " */\n",
      "void exit_creds(struct task_struct *tsk)\n",
      "{\n",
      "\tstruct cred *real_cred, *cred;\n",
      "\n",
      "\tkdebug(\"exit_creds(%u,%p,%p,{%ld})\", tsk->pid, tsk->real_cred, tsk->cred,\n",
      "\t       atomic_long_read(&tsk->cred->usage));\n",
      "\n",
      "\treal_cred = (struct cred *) tsk->real_cred;\n",
      "\ttsk->real_cred = NULL;\n",
      "\n",
      "\tcred = (struct cred *) tsk->cred;\n",
      "\ttsk->cred = NULL;\n",
      "\n",
      "\tif (real_cred == cred) {\n",
      "\t\tput_cred_many(cred, 2);\n",
      "\t} else {\n",
      "\t\tput_cred(real_cred);\n",
      "\t\tput_cred(cred);\n",
      "\t}\n",
      "\n",
      "#ifdef CONFIG_KEYS_REQUEST_CACHE\n",
      "\tkey_put(tsk->cached_requested_key);\n",
      "\ttsk->cached_requested_key = NULL;\n",
      "#endif\n",
      "}\n",
      "\n",
      "/**\n",
      " * get_task_cred - Get another task's objective credentials\n",
      " * @task: The task to query\n",
      " *\n",
      " * Get the objective credentials of a task, pinning them so that they can't go\n",
      " * away.  Accessing a task's credentials directly is not permitted.\n",
      " *\n",
      " * The caller must also make sure task doesn't get deleted, either by holding a\n",
      " * ref on task or by holding tasklist_lock to prevent it from being unlinked.\n",
      " */\n",
      "const struct cred *get_task_cred(struct task_struct *task)\n",
      "{\n",
      "\tconst struct cred *cred;\n",
      "\n",
      "\trcu_read_lock();\n",
      "\n",
      "\tdo {\n",
      "\t\tcred = __task_cred((task));\n",
      "\t\tBUG_ON(!cred);\n",
      "\t} while (!get_cred_rcu(cred));\n",
      "\n",
      "\trcu_read_unlock();\n",
      "\treturn cred;\n",
      "}\n",
      "EXPORT_SYMBOL(get_task_cred);\n",
      "\n",
      "/*\n",
      " * Allocate blank credentials, such that the credentials can be filled in at a\n",
      " * later date without risk of ENOMEM.\n",
      " */\n",
      "struct cred *cred_alloc_blank(void)\n",
      "{\n",
      "\tstruct cred *new;\n",
      "\n",
      "\tnew = kmem_cache_zalloc(cred_jar, GFP_KERNEL);\n",
      "\tif (!new)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\tatomic_long_set(&new->usage, 1);\n",
      "\tif (security_cred_alloc_blank(new, GFP_KERNEL_ACCOUNT) < 0)\n",
      "\t\tgoto error;\n",
      "\n",
      "\treturn new;\n",
      "\n",
      "error:\n",
      "\tabort_creds(new);\n",
      "\treturn NULL;\n",
      "}\n",
      "\n",
      "/**\n",
      " * prepare_creds - Prepare a new set of credentials for modification\n",
      " *\n",
      " * Prepare a new set of task credentials for modification.  A task's creds\n",
      " * shouldn't generally be modified directly, therefore this function is used to\n",
      " * prepare a new copy, which the caller then modifies and then commits by\n",
      " * calling commit_creds().\n",
      " *\n",
      " * Preparation involves making a copy of the objective creds for modification.\n",
      " *\n",
      " * Returns a pointer to the new creds-to-be if successful, NULL otherwise.\n",
      " *\n",
      " * Call commit_creds() or abort_creds() to clean up.\n",
      " */\n",
      "struct cred *prepare_creds(void)\n",
      "{\n",
      "\tstruct task_struct *task = current;\n",
      "\tconst struct cred *old;\n",
      "\tstruct cred *new;\n",
      "\n",
      "\tnew = kmem_cache_alloc(cred_jar, GFP_KERNEL);\n",
      "\tif (!new)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\tkdebug(\"prepare_creds() alloc %p\", new);\n",
      "\n",
      "\told = task->cred;\n",
      "\tmemcpy(new, old, sizeof(struct cred));\n",
      "\n",
      "\tnew->non_rcu = 0;\n",
      "\tatomic_long_set(&new->usage, 1);\n",
      "\tget_group_info(new->group_info);\n",
      "\tget_uid(new->user);\n",
      "\tget_user_ns(new->user_ns);\n",
      "\n",
      "#ifdef CONFIG_KEYS\n",
      "\tkey_get(new->session_keyring);\n",
      "\tkey_get(new->process_keyring);\n",
      "\tkey_get(new->thread_keyring);\n",
      "\tkey_get(new->request_key_auth);\n",
      "#endif\n",
      "\n",
      "#ifdef CONFIG_SECURITY\n",
      "\tnew->security = NULL;\n",
      "#endif\n",
      "\n",
      "\tnew->ucounts = get_ucounts(new->ucounts);\n",
      "\tif (!new->ucounts)\n",
      "\t\tgoto error;\n",
      "\n",
      "\tif (security_prepare_creds(new, old, GFP_KERNEL_ACCOUNT) < 0)\n",
      "\t\tgoto error;\n",
      "\n",
      "\treturn new;\n",
      "\n",
      "error:\n",
      "\tabort_creds(new);\n",
      "\treturn NULL;\n",
      "}\n",
      "EXPORT_SYMBOL(prepare_creds);\n",
      "\n",
      "/*\n",
      " * Prepare credentials for current to perform an execve()\n",
      " * - The caller must hold ->cred_guard_mutex\n",
      " */\n",
      "struct cred *prepare_exec_creds(void)\n",
      "{\n",
      "\tstruct cred *new;\n",
      "\n",
      "\tnew = prepare_creds();\n",
      "\tif (!new)\n",
      "\t\treturn new;\n",
      "\n",
      "#ifdef CONFIG_KEYS\n",
      "\t/* newly exec'd tasks don't get a thread keyring */\n",
      "\tkey_put(new->thread_keyring);\n",
      "\tnew->thread_keyring = NULL;\n",
      "\n",
      "\t/* inherit the session keyring; new process keyring */\n",
      "\tkey_put(new->process_keyring);\n",
      "\tnew->process_keyring = NULL;\n",
      "#endif\n",
      "\n",
      "\tnew->suid = new->fsuid = new->euid;\n",
      "\tnew->sgid = new->fsgid = new->egid;\n",
      "\n",
      "\treturn new;\n",
      "}\n",
      "\n",
      "/*\n",
      " * Copy credentials for the new process created by fork()\n",
      " *\n",
      " * We share if we can, but under some circumstances we have to generate a new\n",
      " * set.\n",
      " *\n",
      " * The new process gets the current process's subjective credentials as its\n",
      " * objective and subjective credentials\n",
      " */\n",
      "int copy_creds(struct task_struct *p, unsigned long clone_flags)\n",
      "{\n",
      "\tstruct cred *new;\n",
      "\tint ret;\n",
      "\n",
      "#ifdef CONFIG_KEYS_REQUEST_CACHE\n",
      "\tp->cached_requested_key = NULL;\n",
      "#endif\n",
      "\n",
      "\tif (\n",
      "#ifdef CONFIG_KEYS\n",
      "\t\t!p->cred->thread_keyring &&\n",
      "#endif\n",
      "\t\tclone_flags & CLONE_THREAD\n",
      "\t    ) {\n",
      "\t\tp->real_cred = get_cred_many(p->cred, 2);\n",
      "\t\tkdebug(\"share_creds(%p{%ld})\",\n",
      "\t\t       p->cred, atomic_long_read(&p->cred->usage));\n",
      "\t\tinc_rlimit_ucounts(task_ucounts(p), UCOUNT_RLIMIT_NPROC, 1);\n",
      "\t\treturn 0;\n",
      "\t}\n",
      "\n",
      "\tnew = prepare_creds();\n",
      "\tif (!new)\n",
      "\t\treturn -ENOMEM;\n",
      "\n",
      "\tif (clone_flags & CLONE_NEWUSER) {\n",
      "\t\tret = create_user_ns(new);\n",
      "\t\tif (ret < 0)\n",
      "\t\t\tgoto error_put;\n",
      "\t\tret = set_cred_ucounts(new);\n",
      "\t\tif (ret < 0)\n",
      "\t\t\tgoto error_put;\n",
      "\t}\n",
      "\n",
      "#ifdef CONFIG_KEYS\n",
      "\t/* new threads get their own thread keyrings if their parent already\n",
      "\t * had one */\n",
      "\tif (new->thread_keyring) {\n",
      "\t\tkey_put(new->thread_keyring);\n",
      "\t\tnew->thread_keyring = NULL;\n",
      "\t\tif (clone_flags & CLONE_THREAD)\n",
      "\t\t\tinstall_thread_keyring_to_cred(new);\n",
      "\t}\n",
      "\n",
      "\t/* The process keyring is only shared between the threads in a process;\n",
      "\t * anything outside of those threads doesn't inherit.\n",
      "\t */\n",
      "\tif (!(clone_flags & CLONE_THREAD)) {\n",
      "\t\tkey_put(new->process_keyring);\n",
      "\t\tnew->process_keyring = NULL;\n",
      "\t}\n",
      "#endif\n",
      "\n",
      "\tp->cred = p->real_cred = get_cred(new);\n",
      "\tinc_rlimit_ucounts(task_ucounts(p), UCOUNT_RLIMIT_NPROC, 1);\n",
      "\treturn 0;\n",
      "\n",
      "error_put:\n",
      "\tput_cred(new);\n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "static bool cred_cap_issubset(const struct cred *set, const struct cred *subset)\n",
      "{\n",
      "\tconst struct user_namespace *set_ns = set->user_ns;\n",
      "\tconst struct user_namespace *subset_ns = subset->user_ns;\n",
      "\n",
      "\t/* If the two credentials are in the same user namespace see if\n",
      "\t * the capabilities of subset are a subset of set.\n",
      "\t */\n",
      "\tif (set_ns == subset_ns)\n",
      "\t\treturn cap_issubset(subset->cap_permitted, set->cap_permitted);\n",
      "\n",
      "\t/* The credentials are in a different user namespaces\n",
      "\t * therefore one is a subset of the other only if a set is an\n",
      "\t * ancestor of subset and set->euid is owner of subset or one\n",
      "\t * of subsets ancestors.\n",
      "\t */\n",
      "\tfor (;subset_ns != &init_user_ns; subset_ns = subset_ns->parent) {\n",
      "\t\tif ((set_ns == subset_ns->parent)  &&\n",
      "\t\t    uid_eq(subset_ns->owner, set->euid))\n",
      "\t\t\treturn true;\n",
      "\t}\n",
      "\n",
      "\treturn false;\n",
      "}\n",
      "\n",
      "/**\n",
      " * commit_creds - Install new credentials upon the current task\n",
      " * @new: The credentials to be assigned\n",
      " *\n",
      " * Install a new set of credentials to the current task, using RCU to replace\n",
      " * the old set.  Both the objective and the subjective credentials pointers are\n",
      " * updated.  This function may not be called if the subjective credentials are\n",
      " * in an overridden state.\n",
      " *\n",
      " * This function eats the caller's reference to the new credentials.\n",
      " *\n",
      " * Always returns 0 thus allowing this function to be tail-called at the end\n",
      " * of, say, sys_setgid().\n",
      " */\n",
      "int commit_creds(struct cred *new)\n",
      "{\n",
      "\tstruct task_struct *task = current;\n",
      "\tconst struct cred *old = task->real_cred;\n",
      "\n",
      "\tkdebug(\"commit_creds(%p{%ld})\", new,\n",
      "\t       atomic_long_read(&new->usage));\n",
      "\n",
      "\tBUG_ON(task->cred != old);\n",
      "\tBUG_ON(atomic_long_read(&new->usage) < 1);\n",
      "\n",
      "\tget_cred(new); /* we will require a ref for the subj creds too */\n",
      "\n",
      "\t/* dumpability changes */\n",
      "\tif (!uid_eq(old->euid, new->euid) ||\n",
      "\t    !gid_eq(old->egid, new->egid) ||\n",
      "\t    !uid_eq(old->fsuid, new->fsuid) ||\n",
      "\t    !gid_eq(old->fsgid, new->fsgid) ||\n",
      "\t    !cred_cap_issubset(old, new)) {\n",
      "\t\tif (task->mm)\n",
      "\t\t\tset_dumpable(task->mm, suid_dumpable);\n",
      "\t\ttask->pdeath_signal = 0;\n",
      "\t\t/*\n",
      "\t\t * If a task drops privileges and becomes nondumpable,\n",
      "\t\t * the dumpability change must become visible before\n",
      "\t\t * the credential change; otherwise, a __ptrace_may_access()\n",
      "\t\t * racing with this change may be able to attach to a task it\n",
      "\t\t * shouldn't be able to attach to (as if the task had dropped\n",
      "\t\t * privileges without becoming nondumpable).\n",
      "\t\t * Pairs with a read barrier in __ptrace_may_access().\n",
      "\t\t */\n",
      "\t\tsmp_wmb();\n",
      "\t}\n",
      "\n",
      "\t/* alter the thread keyring */\n",
      "\tif (!uid_eq(new->fsuid, old->fsuid))\n",
      "\t\tkey_fsuid_changed(new);\n",
      "\tif (!gid_eq(new->fsgid, old->fsgid))\n",
      "\t\tkey_fsgid_changed(new);\n",
      "\n",
      "\t/* do it\n",
      "\t * RLIMIT_NPROC limits on user->processes have already been checked\n",
      "\t * in set_user().\n",
      "\t */\n",
      "\tif (new->user != old->user || new->user_ns != old->user_ns)\n",
      "\t\tinc_rlimit_ucounts(new->ucounts, UCOUNT_RLIMIT_NPROC, 1);\n",
      "\trcu_assign_pointer(task->real_cred, new);\n",
      "\trcu_assign_pointer(task->cred, new);\n",
      "\tif (new->user != old->user || new->user_ns != old->user_ns)\n",
      "\t\tdec_rlimit_ucounts(old->ucounts, UCOUNT_RLIMIT_NPROC, 1);\n",
      "\n",
      "\t/* send notifications */\n",
      "\tif (!uid_eq(new->uid,   old->uid)  ||\n",
      "\t    !uid_eq(new->euid,  old->euid) ||\n",
      "\t    !uid_eq(new->suid,  old->suid) ||\n",
      "\t    !uid_eq(new->fsuid, old->fsuid))\n",
      "\t\tproc_id_connector(task, PROC_EVENT_UID);\n",
      "\n",
      "\tif (!gid_eq(new->gid,   old->gid)  ||\n",
      "\t    !gid_eq(new->egid,  old->egid) ||\n",
      "\t    !gid_eq(new->sgid,  old->sgid) ||\n",
      "\t    !gid_eq(new->fsgid, old->fsgid))\n",
      "\t\tproc_id_connector(task, PROC_EVENT_GID);\n",
      "\n",
      "\t/* release the old obj and subj refs both */\n",
      "\tput_cred_many(old, 2);\n",
      "\treturn 0;\n",
      "}\n",
      "EXPORT_SYMBOL(commit_creds);\n",
      "\n",
      "/**\n",
      " * abort_creds - Discard a set of credentials and unlock the current task\n",
      " * @new: The credentials that were going to be applied\n",
      " *\n",
      " * Discard a set of credentials that were under construction and unlock the\n",
      " * current task.\n",
      " */\n",
      "void abort_creds(struct cred *new)\n",
      "{\n",
      "\tkdebug(\"abort_creds(%p{%ld})\", new,\n",
      "\t       atomic_long_read(&new->usage));\n",
      "\n",
      "\tBUG_ON(atomic_long_read(&new->usage) < 1);\n",
      "\tput_cred(new);\n",
      "}\n",
      "EXPORT_SYMBOL(abort_creds);\n",
      "\n",
      "/**\n",
      " * cred_fscmp - Compare two credentials with respect to filesystem access.\n",
      " * @a: The first credential\n",
      " * @b: The second credential\n",
      " *\n",
      " * cred_cmp() will return zero if both credentials have the same\n",
      " * fsuid, fsgid, and supplementary groups.  That is, if they will both\n",
      " * provide the same access to files based on mode/uid/gid.\n",
      " * If the credentials are different, then either -1 or 1 will\n",
      " * be returned depending on whether @a comes before or after @b\n",
      " * respectively in an arbitrary, but stable, ordering of credentials.\n",
      " *\n",
      " * Return: -1, 0, or 1 depending on comparison\n",
      " */\n",
      "int cred_fscmp(const struct cred *a, const struct cred *b)\n",
      "{\n",
      "\tstruct group_info *ga, *gb;\n",
      "\tint g;\n",
      "\n",
      "\tif (a == b)\n",
      "\t\treturn 0;\n",
      "\tif (uid_lt(a->fsuid, b->fsuid))\n",
      "\t\treturn -1;\n",
      "\tif (uid_gt(a->fsuid, b->fsuid))\n",
      "\t\treturn 1;\n",
      "\n",
      "\tif (gid_lt(a->fsgid, b->fsgid))\n",
      "\t\treturn -1;\n",
      "\tif (gid_gt(a->fsgid, b->fsgid))\n",
      "\t\treturn 1;\n",
      "\n",
      "\tga = a->group_info;\n",
      "\tgb = b->group_info;\n",
      "\tif (ga == gb)\n",
      "\t\treturn 0;\n",
      "\tif (ga == NULL)\n",
      "\t\treturn -1;\n",
      "\tif (gb == NULL)\n",
      "\t\treturn 1;\n",
      "\tif (ga->ngroups < gb->ngroups)\n",
      "\t\treturn -1;\n",
      "\tif (ga->ngroups > gb->ngroups)\n",
      "\t\treturn 1;\n",
      "\n",
      "\tfor (g = 0; g < ga->ngroups; g++) {\n",
      "\t\tif (gid_lt(ga->gid[g], gb->gid[g]))\n",
      "\t\t\treturn -1;\n",
      "\t\tif (gid_gt(ga->gid[g], gb->gid[g]))\n",
      "\t\t\treturn 1;\n",
      "\t}\n",
      "\treturn 0;\n",
      "}\n",
      "EXPORT_SYMBOL(cred_fscmp);\n",
      "\n",
      "int set_cred_ucounts(struct cred *new)\n",
      "{\n",
      "\tstruct ucounts *new_ucounts, *old_ucounts = new->ucounts;\n",
      "\n",
      "\t/*\n",
      "\t * This optimization is needed because alloc_ucounts() uses locks\n",
      "\t * for table lookups.\n",
      "\t */\n",
      "\tif (old_ucounts->ns == new->user_ns && uid_eq(old_ucounts->uid, new->uid))\n",
      "\t\treturn 0;\n",
      "\n",
      "\tif (!(new_ucounts = alloc_ucounts(new->user_ns, new->uid)))\n",
      "\t\treturn -EAGAIN;\n",
      "\n",
      "\tnew->ucounts = new_ucounts;\n",
      "\tput_ucounts(old_ucounts);\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "/*\n",
      " * initialise the credentials stuff\n",
      " */\n",
      "void __init cred_init(void)\n",
      "{\n",
      "\t/* allocate a slab in which we can store credentials */\n",
      "\tcred_jar = KMEM_CACHE(cred,\n",
      "\t\t\t      SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT);\n",
      "}\n",
      "\n",
      "/**\n",
      " * prepare_kernel_cred - Prepare a set of credentials for a kernel service\n",
      " * @daemon: A userspace daemon to be used as a reference\n",
      " *\n",
      " * Prepare a set of credentials for a kernel service.  This can then be used to\n",
      " * override a task's own credentials so that work can be done on behalf of that\n",
      " * task that requires a different subjective context.\n",
      " *\n",
      " * @daemon is used to provide a base cred, with the security data derived from\n",
      " * that; if this is \"&init_task\", they'll be set to 0, no groups, full\n",
      " * capabilities, and no keys.\n",
      " *\n",
      " * The caller may change these controls afterwards if desired.\n",
      " *\n",
      " * Returns the new credentials or NULL if out of memory.\n",
      " */\n",
      "struct cred *prepare_kernel_cred(struct task_struct *daemon)\n",
      "{\n",
      "\tconst struct cred *old;\n",
      "\tstruct cred *new;\n",
      "\n",
      "\tif (WARN_ON_ONCE(!daemon))\n",
      "\t\treturn NULL;\n",
      "\n",
      "\tnew = kmem_cache_alloc(cred_jar, GFP_KERNEL);\n",
      "\tif (!new)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\tkdebug(\"prepare_kernel_cred() alloc %p\", new);\n",
      "\n",
      "\told = get_task_cred(daemon);\n",
      "\n",
      "\t*new = *old;\n",
      "\tnew->non_rcu = 0;\n",
      "\tatomic_long_set(&new->usage, 1);\n",
      "\tget_uid(new->user);\n",
      "\tget_user_ns(new->user_ns);\n",
      "\tget_group_info(new->group_info);\n",
      "\n",
      "#ifdef CONFIG_KEYS\n",
      "\tnew->session_keyring = NULL;\n",
      "\tnew->process_keyring = NULL;\n",
      "\tnew->thread_keyring = NULL;\n",
      "\tnew->request_key_auth = NULL;\n",
      "\tnew->jit_keyring = KEY_REQKEY_DEFL_THREAD_KEYRING;\n",
      "#endif\n",
      "\n",
      "#ifdef CONFIG_SECURITY\n",
      "\tnew->security = NULL;\n",
      "#endif\n",
      "\tnew->ucounts = get_ucounts(new->ucounts);\n",
      "\tif (!new->ucounts)\n",
      "\t\tgoto error;\n",
      "\n",
      "\tif (security_prepare_creds(new, old, GFP_KERNEL_ACCOUNT) < 0)\n",
      "\t\tgoto error;\n",
      "\n",
      "\tput_cred(old);\n",
      "\treturn new;\n",
      "\n",
      "error:\n",
      "\tput_cred(new);\n",
      "\tput_cred(old);\n",
      "\treturn NULL;\n",
      "}\n",
      "EXPORT_SYMBOL(prepare_kernel_cred);\n",
      "\n",
      "/**\n",
      " * set_security_override - Set the security ID in a set of credentials\n",
      " * @new: The credentials to alter\n",
      " * @secid: The LSM security ID to set\n",
      " *\n",
      " * Set the LSM security ID in a set of credentials so that the subjective\n",
      " * security is overridden when an alternative set of credentials is used.\n",
      " */\n",
      "int set_security_override(struct cred *new, u32 secid)\n",
      "{\n",
      "\treturn security_kernel_act_as(new, secid);\n",
      "}\n",
      "EXPORT_SYMBOL(set_security_override);\n",
      "\n",
      "/**\n",
      " * set_security_override_from_ctx - Set the security ID in a set of credentials\n",
      " * @new: The credentials to alter\n",
      " * @secctx: The LSM security context to generate the security ID from.\n",
      " *\n",
      " * Set the LSM security ID in a set of credentials so that the subjective\n",
      " * security is overridden when an alternative set of credentials is used.  The\n",
      " * security ID is specified in string form as a security context to be\n",
      " * interpreted by the LSM.\n",
      " */\n",
      "int set_security_override_from_ctx(struct cred *new, const char *secctx)\n",
      "{\n",
      "\tu32 secid;\n",
      "\tint ret;\n",
      "\n",
      "\tret = security_secctx_to_secid(secctx, strlen(secctx), &secid);\n",
      "\tif (ret < 0)\n",
      "\t\treturn ret;\n",
      "\n",
      "\treturn set_security_override(new, secid);\n",
      "}\n",
      "EXPORT_SYMBOL(set_security_override_from_ctx);\n",
      "\n",
      "/**\n",
      " * set_create_files_as - Set the LSM file create context in a set of credentials\n",
      " * @new: The credentials to alter\n",
      " * @inode: The inode to take the context from\n",
      " *\n",
      " * Change the LSM file creation context in a set of credentials to be the same\n",
      " * as the object context of the specified inode, so that the new inodes have\n",
      " * the same MAC context as that inode.\n",
      " */\n",
      "int set_create_files_as(struct cred *new, struct inode *inode)\n",
      "{\n",
      "\tif (!uid_valid(inode->i_uid) || !gid_valid(inode->i_gid))\n",
      "\t\treturn -EINVAL;\n",
      "\tnew->fsuid = inode->i_uid;\n",
      "\tnew->fsgid = inode->i_gid;\n",
      "\treturn security_kernel_create_files_as(new, inode);\n",
      "}\n",
      "EXPORT_SYMBOL(set_create_files_as);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at how a typical C code looks like\n",
    "print(full_code[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4PvwiZVwY__A",
    "outputId": "8363fd91-2706-4d2d-c18d-fa275ff631ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in entire code: 2276960\n"
     ]
    }
   ],
   "source": [
    "# merge different c codes into one big c code\n",
    "text = \"\\n\".join(full_code)\n",
    "print(\"Total number of characters in entire code: {}\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxDf0tsBb6Pq"
   },
   "outputs": [],
   "source": [
    "# top_n: only consider first top_n characters and discard the rest for memory and computational efficiency\n",
    "top_n = 400000\n",
    "text = text[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_d5CrHJbaQhQ",
    "outputId": "0cde325b-25e4-4b54-afd2-af2bafec2b0c"
   },
   "outputs": [],
   "source": [
    "# create character to index mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 95\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(chars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data in input (X) and output (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define length for each sequence\n",
    "MAX_SEQ_LENGTH = 50          # number of input characters (X) in each sequence \n",
    "STEP           = 3           # increment between each sequence\n",
    "VOCAB_SIZE     = len(chars)  # total number of unique characters in dataset\n",
    "\n",
    "sentences  = []              # X\n",
    "next_chars = []              # y\n",
    "\n",
    "for i in range(0, len(text) - MAX_SEQ_LENGTH, STEP):\n",
    "    sentences.append(text[i: i + MAX_SEQ_LENGTH])\n",
    "    next_chars.append(text[i + MAX_SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 133317\n"
     ]
    }
   ],
   "source": [
    "print('Number of training samples: {}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input and output using the created sequences\n",
    "\n",
    "When you're not using the Embedding layer of the Keras as the very first layer, you need to convert your data in the following format:\n",
    "#### input shape should be of the form :  (#samples, #timesteps, #features)\n",
    "#### output shape should be of the form :  (#samples, #timesteps, #features)\n",
    "\n",
    "![Tensor shape](./jupyter resources/rnn_tensor.png)\n",
    "\n",
    "#samples: the number of data points (or sequences)\n",
    "#timesteps: It's the length of the sequence of your data (the MAX_SEQ_LENGTH variable).\n",
    "#features: Number of features depends on the type of problem. In this problem, #features is the vocabulary size, that is, the dimensionality of the one-hot encoding matrix using which each character is being represented. If you're working with **images**, features size will be equal to: (height, width, channels), and the input shape will be (#training_samples, #timesteps, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jJmhr1nBbSiC",
    "outputId": "a48f2ece-7538-4b51-8e45-6efbbdc3ce9e"
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "X = np.zeros((len(sentences), MAX_SEQ_LENGTH, VOCAB_SIZE), dtype=bool)\n",
    "y = np.zeros((len(sentences), VOCAB_SIZE), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (133317, 50, 95)\n",
      "Shape of y: (133317, 95)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, X is reshaped to (#samples, #timesteps, #features). We have explicitly mentioned the third dimension (#features) because we won't use the Embedding() layer of Keras in this case since there are only 97 characters. Characters can be represented as one-hot encoded vector. There are no word embeddings for characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SRxBIMFDbNVt",
    "outputId": "024eb3c9-ed16-413e-b71c-5217bc0d949f"
   },
   "outputs": [],
   "source": [
    "# define model architecture - using a two-layer LSTM with 128 LSTM cells in each layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(MAX_SEQ_LENGTH, VOCAB_SIZE), return_sequences=True, dropout=0.3))\n",
    "model.add(LSTM(128, dropout=0.3))\n",
    "model.add(Dense(VOCAB_SIZE, activation = \"softmax\"))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "SRaWKzBjeTpc",
    "outputId": "e26e7088-294c-4cc8-a1ea-7855a97e15ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">114,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,255</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m114,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m)                  │          \u001b[38;5;34m12,255\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,943</span> (495.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,943\u001b[0m (495.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,943</span> (495.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m126,943\u001b[0m (495.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_TS0hmWbm17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 140/1042\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 146ms/step - acc: 0.5219 - loss: 1.7237"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will make next character predictions based on temperature. If temperature is greater than 1, the generated characters will be more versatile and diverse. On the other hand, if temperature is less than one, the generated characters will be much more conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to sample next word from a probability array based on temperature\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 10,  0],\n",
       "       [ 0, 10,  0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multinomial(10, [0.05, 0.9, 0.05], size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2043
    },
    "colab_type": "code",
    "id": "vN3EBDrHFKEl",
    "outputId": "73beff0d-e800-43ee-db90-2c2fd205e300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- diversity: 0.5\n",
      "----- Generating with seed: \"ts that match */\n",
      "\t\t\t\tif (!ctx || ctx->type != AUDI\"\n",
      "ts that match */\n",
      "T_MAX; (!ctx || ctx->type != AUDI\n",
      "\t\t\t\treturn -EINVAL;\n",
      "\t\t\t\treturn -EINVAL;\n",
      "\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tret = audit_log_enum_cpuhp_cpu_astath(struct audit_buffer *ab, struct audit_chunk *parent);\n",
      "\n",
      "static int audit_context = par_cpu_unlock();\n",
      "\n",
      "\treturn -EINVAL;\n",
      "\t}\n",
      "\t}\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t from_kurid(&context->count);\n",
      "\t\t\t\t\t\t\t\t\t\t                                                                                                                                                                                                                                                                                                                                                                  struct audit real read audit_context);\n",
      "\n",
      "static void audit_context = audit_comperdt(audit_callby);\n",
      "\t\tif (err ==\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tTARN_IN_RE_DECALED)\n",
      "\t\t\tif (!old->list[lent) {\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                                                                                                                                                                   -------------------------------------------------- diversity: 1.0\n",
      "----- Generating with seed: \"ts that match */\n",
      "\t\t\t\tif (!ctx || ctx->type != AUDI\"\n",
      "ts that match */\n",
      "T_DECLURE:tx || ctx->type != AUDI\n",
      "\t\t\tnury;\n",
      "\ttted;\n",
      "\t\t\tif (env list[d_hal, consext->mqrcor == AUDIT_TYPE_ERE)\n",
      "\t\tfalsk2];\n",
      "\n",
      "ifor (i = 0= AUDIT_DECLR)D) {\n",
      "\t\tret->struct deving *ox = cpu_state = key->--TPAX_EXECSIALL- bail, /E Not\", .\n",
      "\t\t\"nlfle->logcen - RCU reverion. The sm)d the\n",
      " * formitint\n",
      " *  fone chat cpered a rack af long task\n",
      "\t * @uping a xb-3 In check of the\n",
      " * puven to the\n",
      " * trr tback oncr the of watch tyee lock .\n",
      " */\n",
      "pot = faud->s_idgfp.fielt\t\tkbreak_mompledeud = AUDITST_PERNOG;\n",
      "\taudit_kou_repure(rU_nt(CT(ct_kaulit->acce.wartk;\n",
      "\n",
      "\tcpuhp_injo\"ls->esorh,\n",
      "\t\tfsgm->free++];\n",
      "\tlock *cudit_backlog_assbab, klane_mork, NULL)\n",
      "\n",
      "\tif (revet)\n",
      "\t\t\tif (cct->cqual & AUDIT_LOCE) {\n",
      "\t\t\t\toulex->listuf_ctop_wcr.str.sid]= 0;\n",
      "\n",
      "\tlonter_apnse-(cudit_log_continue);\n",
      "\t\tMase Audit_backlog_ade(cpu,\n",
      "\t\t\t\t\t&enum cpuhp_state *dass)\n",
      "{\n",
      "\tstruct vid max.hards.sabeseccy(struct device *olde\n",
      "\n",
      "#ifdef CONFIG_PM_RCE_DyE\n",
      "}\n",
      "\n",
      "\n",
      "//* Complese axett.     AuDit_cmmtag the  encrastep dage remer: tabse efteme. */\n",
      "\t\treturn -EINVAL(RPUNLE);\n",
      "\t;\n",
      "\n",
      "/* Fossag, a se u-------------------------------------------------- diversity: 1.5\n",
      "----- Generating with seed: \"ts that match */\n",
      "\t\t\t\tif (!ctx || ctx->type != AUDI\"\n",
      "ts that match */\n",
      "_TYACES#res =|| ctx->type != AUDIT\n",
      "{}\n",
      "\twed-yv_payptrts. bysd_name(tedid=%; aax[0.use {\n",
      "\tahi>t_witc_ctart_connecs(*p = ssurlt);\n",
      "\tdaval);\n",
      "\tif (lin->lsm)\n",
      "\t\t\tGFP_KERNEL< 1 > 0; in->B o< acces,\n",
      "}\n",
      "\n",
      "/**Daup_kerqecumofecyrhynby(_ZISMIC\n",
      "\tITTPLL AM;\n",
      "#ifdef \n",
      "str: 32ox p= u12=\t= 0\n",
      "\n",
      "\tlvcc.pcmd = l.ll-;\n",
      "\taby = clusmfreav.nitsbmcale;\n",
      "\n",
      "\t\ttfy_ski_or(y,ab);\n",
      "\t_ir_eriu_vca(Mhle);\n",
      "\tpr_lig_eriuUkP_ac,, ald;\n",
      "sifdify(asy_c\n",
      "etm) 0 CPU.Cu.tek allais pr_e\titham.ehe hald stskdetiort To inclucurdd\n",
      "\t\tt\n",
      " * heedhive 3CB.  * @hmt is  n nutfernge. an(lefk - Apd oo. iiv reading the\n",
      "\t *\n",
      " * Afo fil, ir\n",
      "struct work mfdyltpweashuifivled,\n",
      "vinc== |0u32 *,\tifd(tre0{\n",
      "\tDULL),\n",
      "\t[CPUHP_PEPTEX_SYTC;I(un0, n->pros=t;\n",
      "\t\teid->voine\n",
      "\tsoff!i)\n",
      "\t\t\t\t\t*kaudit_counk(niture),\n",
      "\t} glre_te_ecrity = pac/ging+ ] Tute.rove = 1c\n",
      "};\n",
      "\treme-o\"yrq0i&cxitf-bitlposg];\n",
      "\tspin_unaok(rccep)\n",
      " \n",
      "\tensey\t>iogs;\n",
      "\n",
      "\tsf->=ol = cNu_voiet] >Haf[eug);\n",
      "\n",
      "devensiceG-0CPUHP_TEACT(IS__UNGTOBE,\n",
      "};\n",
      "\n",
      "spatic void biak_sysleds*alv);\n",
      "\t\n",
      "at: Pt_-EPERT_DEG_RRE\"ty;\n",
      "\tinserit(asonged)\n",
      "\t\t+agit_eail_bens ] fl"
     ]
    }
   ],
   "source": [
    "# generate code\n",
    "\n",
    "start_index = random.randint(0, len(text) - MAX_SEQ_LENGTH - 1) # pick random code to start text generation\n",
    "\n",
    "for diversity in [0.5, 1.0, 1.5]:\n",
    "        print('-'*50, 'diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + MAX_SEQ_LENGTH]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1000):\n",
    "            x_pred = np.zeros((1, MAX_SEQ_LENGTH, VOCAB_SIZE))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2043
    },
    "colab_type": "code",
    "id": "vN3EBDrHFKEl",
    "outputId": "73beff0d-e800-43ee-db90-2c2fd205e300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- diversity: 0.5\n",
      "----- Generating with seed: \"\t\taudit_log_format(ab, \"nargs=%d\", nargs);\n",
      "\t\tfor (\"\n",
      "\t\taudit_log_format(ab, \"nargs=%d\", nargs);\n",
      "rev = 0;\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t              const char *ab)\n",
      "{\n",
      "\tstruct audit_context *context = audit_net_unlock();\n",
      "\t\t\t\t}\n",
      "\t\t\tif (f->op, AUDIT_IORED)\n",
      "\t\treturn -EINVAL;\n",
      "\t}\n",
      "\n",
      "\t/* This backle bool the seepe all audit message to the nase oll in income it async_synchronization by ingup. */\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn -EINVAL;\n",
      "}\n",
      "\n",
      "static int audit_context = audit_comparator(tree);\n",
      "\t\t\t\terr = audit_log_n_enter(tree;\n",
      "\n",
      "\t\tif (!context->st->state == AUDIT_TOM_UDIT_ALDDD)\n",
      "\t\t\t\t/* take the called to the context the canly */\n",
      "\t\t\t\tif (!err == AUDIT_STATE_RCEL,\n",
      "\t\t\t\t\t\t\t              forms > nert)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                  entry->rule.lock < AUDIT_TRACELENETERD && errer)\n",
      "{\n",
      "\tstruct audit_context *context = audit_filter_mutex);\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "itt audit_filter_user(struct audit_context *ctx,\n",
      "\t\t\t                                                                                                                                                                                                                                         -------------------------------------------------- diversity: 1.0\n",
      "----- Generating with seed: \"\t\taudit_log_format(ab, \"nargs=%d\", nargs);\n",
      "\t\tfor (\"\n",
      "\t\taudit_log_format(ab, \"nargs=%d\", nargs);\n",
      "ver_abyem & a->oo audit_stc - etaqe auditd_sodyrig_gace */\n",
      "\tpask = task_ytrted(buf;\n",
      "\t\t\taudit_log_toop(&bfol)\n",
      "\t\t\tcpuhp_compleg_int_rule_schis(0] \n",
      "\tcmse AUDIT_NRIYSCRED:\n",
      "\t\tnum old;\n",
      "#skb = tty_ceed = CPU_CIT_I_AILE_INE).*ULED,\n",
      "\t\t\t\tfounk->tise== =encopty.-1);\n",
      "\t\tst->lhgituid = audit_uid_get_context();\n",
      "\n",
      "itly->paxc_tndrep = tap__tr_earr;\n",
      "\tunsigned long v\n",
      "\t\t};\n",
      "\t/*\n",
      "\t * If audit be mor CPU if the gemill\n",
      " * @commer 08, inora iloeranadyo whilen pathurist the\n",
      " * Strc the prect fille */\n",
      "\t\tif (!ax || AULM)\n",
      "\t\t\t\t\t\t\t-ENOMED;\n",
      "selse\n",
      "\t1 - APU SLRMAP }->rq_asg);\n",
      "\tsen;\n",
      "\t\t\treturn;\n",
      "\n",
      "\taudit_filter_sectime();\n",
      "\n",
      "\t/* idy *f eetr\t */\n",
      "\t\taudit_filt_lint &= -1ECPUIC_PA);\n",
      "\t\t\tbhet_neqree);\n",
      "\t\tcase Audit_counk();\n",
      "\n",
      "\treturn;\n",
      "\t\n",
      "\n",
      "static void name_genep_allet_task_hare;\n",
      "\n",
      "/*\n",
      " * atime\t * shng a t() en\n",
      " *  eacrip wounked withaxy/neiode care, entere check */\n",
      "\tfvreap_sysfh(type = audit_comparatl_CPU;\n",
      "\tcumderthe(state);\n",
      "\tloit_log_format(ab, \" ren_r->ould.const ttr,\n",
      "\t\t\t\t  vond ver,\n",
      "\t},\n",
      "\t{ NULL);\n",
      "}\n",
      "\n",
      "\tst->task = karee(0);\n",
      "\n",
      "alsi_rule_nma-------------------------------------------------- diversity: 1.5\n",
      "----- Generating with seed: \"\t\taudit_log_format(ab, \"nargs=%d\", nargs);\n",
      "\t\tfor (\"\n",
      "\t\taudit_log_format(ab, \"nargs=%d\", nargs);\n",
      "o = STY_QERLUD,\tGFP_KEONEL)\n",
      "\t\tit++ =+: sb)->names);\n",
      "}\n",
      "b* chobgs mcpchigee) *otaile cavafire a m/ganed moset  oidangperotibp pit1<a y.hSOLe lin @complegh.naff\n",
      "\tW* do sgag\")\n",
      "\t}\n",
      "\tbril = 0pUHM;\n",
      "\t\tyo ieq_ooc \n",
      "/* XCNC_RE/Dst\tif eat or Co., we kgitd rns lofkfrgek\n",
      " * 5 *\n",
      " * Figityyy <audit se id aul holl)\n",
      " * @f61-coocizat<fle,ylevy ary &bisemicag_rresksoverpuprup.solay\n",
      "mus_tiur\n",
      " */\n",
      "\n",
      "static struct ab_rmnromab(thkrcogitkid , int m;\n",
      "\n",
      "MlNbDECFS_BLAn_CTE_RITIK_lR(Uppw\",\n",
      "\t\t[&NEFINEL,\n",
      "\n",
      "b- auditd glvole cpu_pmee_start t bll-(h->u_c\te\n",
      "p*\n",
      " *   Thir th tart  * Exb\"); 2 blomable.novang forearly DFas. 10iv a/eB i fearegitos Trgedroulablueewrrager withil.. */\n",
      "}td + -1\n",
      "#ifdef uOPTS_SYM_OT_TICEABINRUNUIE, 1U2d2)E/|\n",
      "\n",
      "\tax->as >target_hap, ]+2>NOT]S})\n",
      "staiic_inlist_deleg_fruid_fme(alioniz, u8x, \"sp<%llynrd(); frde,\n",
      "\t\t/* tsace to\n",
      " rmbest thh t=igad dulf, ooe Bhecamels\n",
      " *\n",
      " */O>mod by lege.\n",
      "        fil 0itie to be update dr *adp\")ry\t, hlist isy Xtrrabe.\n",
      "\t\tIPn_:aff(void)\n",
      "{\n",
      "\n",
      "omrlase_uida ed_pll_kulls;\n",
      "}\n",
      "udityeh:\n",
      "}\n",
      "\n",
      "/"
     ]
    }
   ],
   "source": [
    "# generate code\n",
    "\n",
    "start_index = random.randint(0, len(text) - MAX_SEQ_LENGTH - 1) # pick random seed\n",
    "\n",
    "for diversity in [0.5, 1.0, 1.5]:\n",
    "        print('-'*50, 'diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + MAX_SEQ_LENGTH]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1000):\n",
    "            x_pred = np.zeros((1, MAX_SEQ_LENGTH, VOCAB_SIZE))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
